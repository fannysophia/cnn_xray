{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic extensions\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import tensorflow imagedatagenerator\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "\n",
    "# Import toolboxes data and result processing\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE TO 16 BATCH SIZE Input image normalization by rescaling, as 255 is maximum pixel value, the value of the image will be between 0 an 1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow of training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/Users/fannysamuelsson/Desktop/AzraProject/traintest/train',      # Input directory for the training images \n",
    "        classes = ['train_no_success','train_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=64,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=True)            \n",
    "\n",
    "# Flow of test images\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "     #  'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "       '/Users/fannysamuelsson/Desktop/AzraProject/traintest/test',   \n",
    "        classes = ['test_no_success','test_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=64,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Input image normalization by rescaling, as 255 is maximum pixel value, the value of the image will be between 0 an 1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow of training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train/',      # Input directory for the training images \n",
    "        classes = ['train_no_success','train_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=16,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=True)            \n",
    "\n",
    "# Flow of test images\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "     #  'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "       'test/',   \n",
    "        classes = ['test_no_success','test_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=16,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=False)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "\n",
    "def enhance_spine(img):\n",
    "    # Normalize to [0, 1] range\n",
    "    img_normalized = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    \n",
    "    # Apply CLAHE to enhance contrast in spine region\n",
    "    img_enhanced = exposure.equalize_adapthist(img_normalized, clip_limit=0.03)\n",
    "    \n",
    "    return img_enhanced  # Will be in [0, 1] range\n",
    "\n",
    "# Data generators with the fixed preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhance_spine,\n",
    "    # No rescale needed since we normalize in the function\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=5,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhance_spine\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'noAugTrain/',      # Input directory for the training images \n",
    "        classes = ['train_no_success','train_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=10,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=True)            \n",
    "\n",
    "# Flow of test images\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "     #  'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "       'noAugTest/',   \n",
    "        classes = ['test_no_success','test_success'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=28,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=True)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New 4 categorical classes structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise pixel values\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training set\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/fannysamuelsson/Desktop/AzraProject/traintest4class/train',\n",
    "    classes=['moderate_pain', 'no_pain', 'severe_pain', 'very_severe_pain'],  # optional fixed order\n",
    "    target_size=(200, 200),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',   # <-- four classes → one‑hot vectors\n",
    "    shuffle=True)\n",
    "\n",
    "# Validation / test set\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    '/Users/fannysamuelsson/Desktop/AzraProject/traintest4class/test',\n",
    "    classes=['moderate_pain', 'no_pain', 'severe_pain', 'very_severe_pain'],\n",
    "    target_size=(200, 200),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part, the set-up of the actual convolutional neural network (CNN) model is described and programmed\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "# The first convolution layer\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.1),\n",
    "    \n",
    "# The second convolution\n",
    "#tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.2),   \n",
    "    \n",
    "# The third convolution\n",
    "\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.3),   \n",
    "    \n",
    "# The fourth convolution\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.4),   \n",
    "\n",
    "# Flatten results to feed into the dense layer\n",
    "tf.keras.layers.Flatten(),\n",
    "\n",
    "# First dense layer\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "#tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Second dense layer\n",
    "#tf.keras.layers.Dense(256, activation='relu'),\n",
    "#tf.keras.layers.BatchNormalization(),\n",
    "#tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Dense output neuron\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# struktur 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRUKTUR 2 In this part, the set-up of the actual convolutional neural network (CNN) model is described and programmed\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "# The first convolution layer\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.1),\n",
    "    \n",
    "# The second convolution\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.2),   \n",
    "    \n",
    "# The third convolution\n",
    "\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.3),   \n",
    "    \n",
    "# The fourth convolution\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.4),   \n",
    "\n",
    "# Flatten results to feed into the dense layer\n",
    "tf.keras.layers.Flatten(),\n",
    "\n",
    "# First dense layer\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Second dense layer\n",
    "tf.keras.layers.Dense(256, activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Dense output neuron\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL In this part, the set-up of the actual convolutional neural network (CNN) model is described and programmed\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "# The first convolution layer\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.1),\n",
    "    \n",
    "# The second convolution\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.2),   \n",
    "    \n",
    "# The third convolution\n",
    "\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.3),   \n",
    "    \n",
    "# The fourth convolution\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu',kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-3)),\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.4),   \n",
    "\n",
    "# Flatten results to feed into the dense layer\n",
    "tf.keras.layers.Flatten(),\n",
    "\n",
    "# First dense layer\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Second dense layer\n",
    "tf.keras.layers.Dense(256, activation='relu'),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "# Dense output neuron\n",
    "tf.keras.layers.Dense(4, activation='softmax')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# 1) load base, freeze it\n",
    "base = EfficientNetB0(weights='imagenet', include_top=False, \n",
    "                      input_shape=(200,200,3))\n",
    "base.trainable = False\n",
    "\n",
    "# 2) build your head\n",
    "inputs = layers.Input((200,200,3))\n",
    "x = base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(4, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model.summary()\n",
    "model.layers\n",
    "model.layers[0].get_weights() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "base = EfficientNetB0(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(200, 200, 3))\n",
    "base.trainable = False\n",
    "\n",
    "\n",
    "inputs  = layers.Input((200, 200, 3))\n",
    "x       = base(inputs, training=False)\n",
    "x       = layers.GlobalAveragePooling2D()(x)\n",
    "x       = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(4, activation='softmax')(x)\n",
    "model   = models.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "for layer in base.layers[-40:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "labels = np.arange(len(train_generator.class_indices))\n",
    "class_weight = dict(enumerate(\n",
    "    compute_class_weight(class_weight='balanced',\n",
    "                         classes=labels,\n",
    "                         y=train_generator.classes)))\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "def step_decay_schedule(initial_lr=1e-5, decay_factor=0.9, step_size=2):\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch / step_size))\n",
    "    return LearningRateScheduler(schedule, verbose=0)\n",
    "\n",
    "lr_sched = step_decay_schedule()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),   # very low LR for FT\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.keras', monitor='val_loss', save_best_only=True\n",
    ")\n",
    "callbacks = [lr_sched, checkpoint]              # no EarlyStopping yet\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model.compile(loss='binary_crossentropy', optimizer='sgd',  metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,        # number of epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Settings for the training-process of the CNN model\n",
    "history = model.fit(train_generator,  \n",
    "      epochs=60, \n",
    "      callbacks=[lr_sched],\n",
    "      # early_stop,checkpoint\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator)\n",
    "      #validation_steps=25,\n",
    "      #steps_per_epoch=30\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss functions and decay schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss, optimizer and metric determination\n",
    "# https://www.jeremyjordan.me/nn-learning-rate/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def step_decay_schedule(initial_lr=1e-4, decay_factor=0.75, step_size=10):\n",
    " \n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-2, decay_factor=0.9, step_size=2)\n",
    "\n",
    "def ordinal_loss(y_true, y_pred):\n",
    "    # Convert one-hot to class indices\n",
    "    true_class = K.argmax(y_true, axis=-1)\n",
    "    pred_class = K.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # Convert to float to compute squared error\n",
    "    true_class = K.cast(true_class, tf.float32)\n",
    "    pred_class = K.cast(pred_class, tf.float32)\n",
    "\n",
    "    return K.mean(K.square(true_class - pred_class))\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    ord_penalty = ordinal_loss(y_true, y_pred)\n",
    "    return ce + 0.5 * ord_penalty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical structure with combined loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL\n",
    "model.compile(loss=combined_loss, optimizer='adam',  metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,        # number of epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Settings for the training-process of the CNN model\n",
    "history = model.fit(train_generator,  \n",
    "      epochs=60, \n",
    "      callbacks=[lr_sched],\n",
    "      # early_stop,checkpoint\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator)\n",
    "      #validation_steps=25,\n",
    "      #steps_per_epoch=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical structure with no modified loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,        # number of epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Settings for the training-process of the CNN model\n",
    "history = model.fit(train_generator,  \n",
    "      epochs=60, \n",
    "      callbacks=[lr_sched],\n",
    "      # early_stop,checkpoint\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator)\n",
    "      #validation_steps=25,\n",
    "      #steps_per_epoch=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd',  metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,        # number of epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Settings for the training-process of the CNN model\n",
    "history = model.fit(train_generator,  \n",
    "      epochs=60, \n",
    "      callbacks=[lr_sched],\n",
    "      # early_stop,checkpoint\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator)\n",
    "      #validation_steps=25,\n",
    "      #steps_per_epoch=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Accuracy validation\n",
    "model.evaluate(train_generator)\n",
    "model.evaluate(validation_generator)\n",
    "\n",
    "# Make predictions\n",
    "STEP_SIZE_TEST = validation_generator.n // validation_generator.batch_size\n",
    "validation_generator.reset()\n",
    "train_generator.reset()\n",
    "\n",
    "# Get predictions\n",
    "preds = model.predict(validation_generator, verbose=1)\n",
    "\n",
    "# Convert predictions to class labels (0 or 1 for binary classification)\n",
    "predicted_classes = (preds > 0.5).astype(int).flatten()\n",
    "\n",
    "# Get true labels\n",
    "true_classes = validation_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Success', 'Success'], \n",
    "            yticklabels=['No Success', 'Success'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for more details\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                          target_names=['No Success', 'Success']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true_classes, preds)\n",
    "\n",
    "# Example find threshold with best balance\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# succes no sucess\n",
    "fpr, tpr, _ = roc_curve(validation_generator.classes, preds)\n",
    "\n",
    "# Area under curve (AUC) calculation\n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "#Plotting of the ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical roc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New categorical\n",
    "import math                   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "steps_val = math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "preds = model.predict(validation_generator, steps=steps_val)\n",
    "# preds.shape  →  (N, 4)\n",
    "\n",
    "\n",
    "y_true_int = validation_generator.classes          # (N,)\n",
    "n_classes  = preds.shape[1]                 # 4\n",
    "y_true_bin = label_binarize(y_true_int, classes=np.arange(n_classes))\n",
    "\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], preds[:, i])\n",
    "    roc_auc[i]        = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), preds.ravel())\n",
    "roc_auc[\"micro\"]              = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "lw = 2\n",
    "\n",
    "class_names = list(validation_generator.class_indices.keys()) \n",
    "colors      = plt.cm.get_cmap('Set1', n_classes)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=lw, color=colors(i),\n",
    "             label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "# micro-average curve\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         color='darkorange', lw=lw+1, linestyle='--',\n",
    "         label=f\"micro-avg (AUC = {roc_auc['micro']:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle=':')\n",
    "plt.xlim([0.0, 1.0]);  plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns              \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "y_pred_int = np.argmax(preds, axis=1)   # (N,)\n",
    "y_true_int = validation_generator.classes      # (N,)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true_int, y_pred_int)\n",
    "print(\"Confusion matrix (raw counts):\\n\", cm)\n",
    "\n",
    "\n",
    "target_names = list(validation_generator.class_indices.keys())\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true_int, y_pred_int, target_names=target_names))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Train counts :\", Counter(train_generator.classes))\n",
    "print(\"Val   counts :\", Counter(val_generator.classes))\n",
    "print(\"Class map    :\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last epoch train acc :\", history.history['accuracy'][-1])\n",
    "print(\"Last epoch val  acc :\", history.history['val_accuracy'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(val_generator.class_indices)       \n",
    "\n",
    "x_batch, y_batch = next(train_generator)\n",
    "print(\"Sample batch labels:\", np.argmax(y_batch, 1)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = model.predict(val_generator)     # shape (N, 4)\n",
    "\n",
    "class_map    = {v:k for k,v in val_generator.class_indices.items()}  # idx name\n",
    "true_indices = val_generator.classes                                  # length N\n",
    "\n",
    "for i in range(min(20, len(true_indices))):\n",
    "    true_lbl = true_indices[i]\n",
    "    pred_lbl = np.argmax(probs[i])\n",
    "    print(f\"{i:02d}  True: {class_map[true_lbl]:15} \"\n",
    "          f\"Pred: {class_map[pred_lbl]:15}  Softmax: {probs[i]}\")\n",
    "\n",
    "plt.hist(np.max(probs, axis=1), bins=20)\n",
    "plt.title(\"Confidence of predicted class\")\n",
    "plt.xlabel(\"Max soft‑max probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate and true postive rate, based on the predictions\n",
    "fpr, tpr, _ = roc_curve(val_generator.classes, preds)\n",
    "\n",
    "# Area under curve (AUC) calculation\n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "#Plotting of the ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance per epoch (x-axis), expressed in accuracy and loss value (y-axis)\n",
    "\n",
    "# Model accuracy estimation\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction values\n",
    "preds = model.predict(validation_generator,\n",
    "                      verbose=1)\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "s = 0; # Surgery success\n",
    "u = 0; # Unsure value\n",
    "n = 0; # No surgery success\n",
    "\n",
    "for i in range(0,len(preds)):\n",
    "    if preds[i]<0.50:\n",
    "      #  print(\"Surgery success\")\n",
    "        s=s+1\n",
    "        \n",
    "    else:\n",
    "     #   print(\"No surgery success: Person has no benefit from surgery\")\n",
    "        n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction value evaluation\n",
    "\n",
    "print(\"There are \" + str(s) + \" people predicted to have surgery success\")\n",
    "print(\"There are \" + str(n) + \" people predicted with no surgery success\")\n",
    "#print(\"There are \" + str(u) + \" people predicted with unsure prediction value\")\n",
    "\n",
    "# Probability evaluation \n",
    "#print(\"There are \" + str(a) + \" prediction with low probability, highly unsure\")\n",
    "#print(\"There are \" + str(b) + \" prediction with medium probability\")\n",
    "#print(\"There are \" + str(c) + \" prediction with high probability, very sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/Users/fannysamuelsson/Desktop/CNOC/AzraProject/test/test_success/9405515_rotated_10.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAD CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# debug step to see the model layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "# grad_cam function\n",
    "def grad_cam_sequential(model, img_array, layer_name, class_idx=0):\n",
    "\n",
    "    layer_idx = None\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layer_name:\n",
    "            layer_idx = idx\n",
    "            break\n",
    "    \n",
    "    if layer_idx is None:\n",
    "        print(f\"Layer {layer_name} not found in model\")\n",
    "        return None, None\n",
    "    \n",
    "    target_layer_output = model.layers[layer_idx].output\n",
    "    final_output = model.output  \n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.input, \n",
    "        outputs=[target_layer_output, final_output]\n",
    "    )\n",
    "    \n",
    "  \n",
    "    img_tensor = np.expand_dims(img_array, axis=0)  # shape (1, H, W, C)\n",
    "    \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = grad_model(img_tensor)\n",
    "        \n",
    "\n",
    "        if isinstance(outputs, list):\n",
    "            conv_outputs = outputs[0]\n",
    "            predictions = outputs[1]\n",
    "        else:\n",
    "            conv_outputs, predictions = outputs\n",
    "        \n",
    "\n",
    "        if isinstance(predictions, list):\n",
    "            predictions = predictions[0]  \n",
    "            \n",
    "\n",
    "        if hasattr(predictions, 'shape') and len(predictions.shape) > 0:\n",
    "            if predictions.shape[-1] == 1:\n",
    "\n",
    "                pred_score = predictions[0][0]\n",
    "            else:\n",
    "\n",
    "                pred_score = predictions[0][class_idx]\n",
    "        else:\n",
    "\n",
    "            pred_score = predictions\n",
    "\n",
    "    grads = tape.gradient(pred_score, conv_outputs)\n",
    "    \n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "\n",
    "    conv_outputs = conv_outputs[0] \n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + tf.keras.backend.epsilon())\n",
    "    heatmap = heatmap.numpy()\n",
    "    heatmap = cv2.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "\n",
    "    original_img = np.uint8(255 * img_array)\n",
    "    if len(original_img.shape) == 2:\n",
    "        original_img = cv2.cvtColor(original_img, cv2.COLOR_GRAY2BGR)\n",
    "    elif original_img.shape[2] == 1:\n",
    "        original_img = cv2.cvtColor(original_img.squeeze(axis=2), cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        original_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    superimposed = cv2.addWeighted(original_img, 0.6, heatmap_colored, 0.4, 0)\n",
    "    \n",
    "    return superimposed, heatmap\n",
    "\n",
    "def display_gradcam_sequential(model, img_path, layer_name, class_idx=0):\n",
    "    \"\"\"Display Grad-CAM for a sequential model\"\"\"\n",
    "    try:\n",
    "\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "        \n",
    "        # Generate Grad-CAM\n",
    "        superimposed_img, heatmap = grad_cam_sequential(model, img_array, layer_name, class_idx)\n",
    "        \n",
    "        if superimposed_img is None:\n",
    "            print(\"Failed to generate Grad-CAM visualization\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(img)  \n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        axes[1].imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(\"Grad-CAM Overlay\")\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "        axes[2].imshow(heatmap, cmap=\"jet\")\n",
    "        axes[2].set_title(\"Activation Heatmap\")\n",
    "        axes[2].axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in display_gradcam_sequential: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_success_image_path ='/Users/fannysamuelsson/Desktop/AzraProject/traintest/train/train_no_success/4081808.png'\n",
    "success_image_path = '/Users/fannysamuelsson/Desktop/AzraProject/traintest/train/train_success/5005384.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if not isinstance(model, tf.keras.Model) or model.input is None:\n",
    "    functional_in  = tf.keras.Input(shape=(200, 200, 3), name=\"img_in\")\n",
    "    functional_out = model(functional_in)          \n",
    "    model          = tf.keras.Model(functional_in, functional_out, name=\"full_cnn\")\n",
    "\n",
    "\n",
    "model.build(input_shape=(None, 200, 200, 3))\n",
    "\n",
    "img_path   = success_image_path     \n",
    "class_idx  = 3                       \n",
    "inner_name = \"conv2d_1\"              \n",
    "\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(200, 200))\n",
    "img = tf.keras.utils.img_to_array(img) / 255.0\n",
    "img = tf.convert_to_tensor(img[None], dtype=tf.float32)   # shape (1,200,200,3)\n",
    "\n",
    "\n",
    "target_layer = model.get_layer(inner_name)   # works directly now\n",
    "probe = tf.keras.Model(inputs=model.input,\n",
    "                       outputs=[target_layer.output, model.output])\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img)\n",
    "    feat_maps, preds = probe(img, training=False)\n",
    "    target_score     = preds[0, class_idx]          # scalar\n",
    "\n",
    "grads = tape.gradient(target_score, feat_maps)\n",
    "\n",
    "print(f\"\\n▶︎ {inner_name}\")\n",
    "print(\"   activ mean:\", feat_maps.numpy().mean(),\n",
    "      \" std:\",        feat_maps.numpy().std())\n",
    "print(\"   grad  mean:\", grads.numpy().mean(),\n",
    "      \" std:\",        grads.numpy().std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if not isinstance(model, tf.keras.Model) or model.input is None:\n",
    "    functional_in  = tf.keras.Input(shape=(200, 200, 3), name=\"img_in\")\n",
    "    functional_out = model(functional_in)          # call Sequential as a layer\n",
    "    model          = tf.keras.Model(functional_in, functional_out, name=\"full_cnn\")\n",
    "\n",
    "\n",
    "model.build(input_shape=(None, 200, 200, 3))\n",
    "\n",
    "\n",
    "img_path   = success_image_path     \n",
    "class_idx  = 3                       \n",
    "inner_name = \"conv2d_1\"            \n",
    "\n",
    "\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(200, 200))\n",
    "img = tf.keras.utils.img_to_array(img) / 255.0\n",
    "img = tf.convert_to_tensor(img[None], dtype=tf.float32)   # shape (1,200,200,3)\n",
    "\n",
    "target_layer = model.get_layer(inner_name) \n",
    "\n",
    "probe = tf.keras.Model(inputs=model.input,\n",
    "                       outputs=[target_layer.output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img)\n",
    "    feat_maps, preds = probe(img, training=False)\n",
    "    target_score     = preds[0, class_idx]          # scalar\n",
    "\n",
    "grads = tape.gradient(target_score, feat_maps)\n",
    "\n",
    "print(f\"\\n▶︎ {inner_name}\")\n",
    "print(\"   activ mean:\", feat_maps.numpy().mean(),\n",
    "      \" std:\",        feat_maps.numpy().std())\n",
    "print(\"   grad  mean:\", grads.numpy().mean(),\n",
    "      \" std:\",        grads.numpy().std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = model.inputs if model.inputs else model.input_shape[1:]\n",
    "outputs = model.outputs if model.outputs else model.layers[-1].output\n",
    "\n",
    "new_model = Model(inputs=inputs, outputs=outputs)\n",
    "print(new_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = tf.zeros((1, 200, 200, 3))\n",
    "model(dummy_input)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "layer_name = \"conv2d_1\"                                    \n",
    "img = image.img_to_array(image.load_img(success_image_path,\n",
    "                                        target_size=(200, 200))) / 255.0\n",
    "\n",
    "act  = tf.keras.Model(model.inputs,\n",
    "                      model.get_layer(layer_name).output)(img[None]).numpy()\n",
    "print(\"mean =\", act.mean(), \" std =\", act.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i}: {layer.name}\")\n",
    "    # first conv layer\n",
    "    display_gradcam_sequential(new_model, success_image_path,layer.name, class_idx=3)\n",
    "\n",
    "    # no_success image\n",
    "    display_gradcam_sequential(new_model, no_success_image_path, layer.name, class_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with first conv layer\n",
    "display_gradcam_sequential(new_model, success_image_path, \"conv2d_3\", class_idx=3)\n",
    "\n",
    "# Try with a no_success image too\n",
    "display_gradcam_sequential(new_model, no_success_image_path, \"conv2d_3\", class_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzraProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
